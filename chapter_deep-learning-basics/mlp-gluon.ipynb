{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多层感知机的简洁实现\n",
    "\n",
    "下面我们使用Gluon来实现上一节中的多层感知机。首先导入所需的包或模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import gluon, init\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "\n",
    "和softmax回归唯一的不同在于，我们多加了一个全连接层作为隐藏层。它的隐藏单元个数为256，并使用ReLU函数作为激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation='relu'),\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu', kernel_initializer=tf.random_normal_initializer(0., 0.01)))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax', kernel_initializer=tf.random_normal_initializer(0., 0.01)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据并训练模型\n",
    "\n",
    "我们使用与[“softmax回归的简洁实现”](softmax-regression-gluon.ipynb)一节中训练softmax回归几乎相同的步骤来读取数据并训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.8076, train acc 0.696, test acc 0.816\n",
      "epoch 2, loss 0.4871, train acc 0.819, test acc 0.851\n",
      "epoch 3, loss 0.4251, train acc 0.842, test acc 0.859\n",
      "epoch 4, loss 0.3996, train acc 0.853, test acc 0.864\n",
      "epoch 5, loss 0.3688, train acc 0.864, test acc 0.846\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.5})\n",
    "num_epochs = 5\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.8402 - accuracy: 0.6857\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4969 - accuracy: 0.8162\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4365 - accuracy: 0.8393\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4046 - accuracy: 0.8500\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3743 - accuracy: 0.8619\n",
      "10000/1 - 0s - loss: 0.3471 - accuracy: 0.8414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4471072820425034, 0.8414]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = tf.keras.datasets.fashion_mnist.load_data()\n",
    "images, labels = train\n",
    "images = images.astype('float32')\n",
    "x_test, y_test = test\n",
    "x_test = x_test.astype('float32')\n",
    "images = images/255.0\n",
    "labels = labels.astype('int32')\n",
    "x_test = x_test/255.0\n",
    "y_test = y_test.astype('int32')\n",
    "fmnist_train_ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "fmnist_train_ds = fmnist_train_ds.shuffle(5000).batch(batch_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.5)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(fmnist_train_ds, epochs=num_epochs)\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* 通过Gluon可以更简洁地实现多层感知机。\n",
    "\n",
    "## 练习\n",
    "\n",
    "* 尝试多加入几个隐藏层，对比上一节中从零开始的实现。\n",
    "* 使用其他的激活函数，看看对结果的影响。\n",
    "\n",
    "\n",
    "\n",
    "## 扫码直达[讨论区](https://discuss.gluon.ai/t/topic/738)\n",
    "\n",
    "![](../img/qr_mlp-gluon.svg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
